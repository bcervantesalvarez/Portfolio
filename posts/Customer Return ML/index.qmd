---
title: "Predicting Customer Returns"
author: Brian Cervantes Alvarez
date: "3-11-2023"
image: return.jpeg
format:
  html:
    toc: true
    toc-location: right
    html-math-method: katex
    page-layout: full
execute: 
  warning: false
  message: false
categories: [R, machine learning, logistical model, data visualization]
---

![](return.jpeg)

## Purpose

In this evaluation, I scrutinized a partially randomly generated customer returns dataset with the objective of forecasting whether a customer would opt to return their purchased item. By employing progressive techniques that advanced from Logistical to Random Forest, I achieved a robust prediction of customer behavior with respect to product returns.


## Approach and Methodology

To ensure proper analysis, I began by loading the necessary libraries and examining the train and test datasets to identify the variables available for analysis. Exploration of the data revealed trends in the number of returns across various variables such as ProductDepartment, ProductSize, and Returns Per State. Given the project objective of predicting the probability of item returns, I selected logistic regression, a well-suited model for binary dependent variables. To prepare the data, I developed a function to transform both the train and test data, ensuring dimensionality was kept in check by removing unnecessary columns such as dates and IDs. Additionally, I updated character data types to factors. Further exploration of the data led to the inclusion of additional features, such as "Season", "CustomerAge", "MSRP", and "PriceRange", that may play a significant role in predicting a customer's probability of returning their product. I ran a Random Forest model and achieved an AUC of 0.625. This indicates moderate predictive power for the model, and suggests that further feature engineering or model tuning may be necessary for better performance.

Initially, I utilized a logistic regression model, however, it required further refinement and tuning. Due to a three-hour time constraint, I focused on building a draft model. While not suitable for production, it is a step towards the right direction.

## Load the required packages

```{r}
library(tidyverse)
library(lubridate)
library(caret)
library(glmnet)
```

## Load the training and test data

```{r}
train <- read_csv("train.csv") 
test <- read_csv("test.csv") 

glimpse(train)
```

## Data Exploration

```{r}
# Look at Product Department
train %>% 
  filter(Returned == 1) %>%
  ggplot(aes(x = ProductDepartment)) +
  geom_bar(fill = "#e67838") +
  labs(title = "Number of Returns Per Department") + 
  theme_minimal()


# Look at Product Size
train %>% 
  filter(Returned == 1) %>%
  ggplot(aes(x = ProductSize)) +
  geom_bar(fill = "#e67838") +
  labs(title = "Number of Returns Per Product Size") + 
  theme_minimal()


#This won't be that valuable
train %>% 
  mutate(CustomerState = factor(CustomerState)) %>%
  filter(Returned == 1) %>%
  ggplot(aes(x = CustomerState)) +
  coord_flip() +
  geom_bar(fill = "#e67838") +
  labs(title = "Number of Returns Per State") + 
  theme_minimal()


```

## Feature Engineering

```{r}
# Creates the features
buildFeatures <- function(ds){
  CurrentDate <- Sys.Date()
  ds %>%
  mutate(Returned = factor(Returned, levels = c(0, 1), labels = c("No","Yes")),
         Season = factor(case_when(months(OrderDate) %in% month.name[1:3] ~ "Winter",
                            months(OrderDate) %in% month.name[4:6] ~ "Spring",
                            months(OrderDate) %in% month.name[7:9] ~ "Summer",
                            months(OrderDate) %in% month.name[10:12] ~ "Fall")), 
         CustomerAge = year(as.period(interval(CustomerBirthDate,CurrentDate))),
         MSRP = round(PurchasePrice / (1 - DiscountPct)),
         PriceRange = factor(case_when(MSRP >= 13 & MSRP <= 30 ~ "$13-$30",
                             MSRP > 30 & MSRP <= 60 ~ "$31-$60",
                             MSRP > 60 & MSRP <= 100 ~ "$61-$100",
                             MSRP > 100 ~ ">$100")),
         ProductDepartment = as.factor(ProductDepartment),
         ProductSize = as.factor(ProductSize),
         CustomerState = as.factor(CustomerState)
  ) %>%
  select(-OrderDate, 
         -CustomerBirthDate, 
         -ID, 
         -OrderID, 
         -CustomerID)
}

IDCols <- test$ID

#Removes and adds columns for train and test sets
train <- buildFeatures(train)
test <- buildFeatures(test)


#Inspect the dataset before training the model
glimpse(train)
summary(train)
table(train$Returned)

```

## Fit a Random Forest Model

```{r}
set.seed(345)

#Model using Random Forest 
ctrl <- trainControl(method = "cv", number = 3, classProbs = TRUE, summaryFunction = twoClassSummary)
fit <- train(Returned ~ .,
             data = train, 
             method = "rf",
             ntree = 50,
             tuneLength = 3,
             metric = "ROC",
             trControl = ctrl)

fit

```

## Make prediction on the test data

```{r}
testPredictions <- predict(fit, newdata = test, type = "prob")[,2]
```

## Writing the Submission File

```{r}
submission <- data.frame(ID = IDCols, Prediction = testPredictions)
write.csv(submission, "submission.csv", row.names = FALSE)
```

## Leftout Features that were considered

```{r}

#odds_ratio <- exp(coef(fit$finalModel))
#data.frame(name = names(odds_ratio), odds_ratio = odds_ratio) %>%  
#  arrange(desc(odds_ratio)) %>% 
#  head()

#Sampling
#train_index <- createDataPartition(returns_train$Returned, times = 1, p = 0.7, list = FALSE)
#train <- returns_train[train_index, ]
#test <- returns_train[-train_index, ]


#Returned = factor(Returned, levels = c(0, 1), labels = c("No","Yes"))
#AgeGroup = factor(case_when(CustomerAge >= 18 & CustomerAge <= 30 ~ "18-30",
#                              CustomerAge > 30 & CustomerAge <= 45 ~ "31-45",
#                              CustomerAge > 45 & CustomerAge <= 60 ~ "46-60",
#                              CustomerAge > 60 ~ ">61"),
#                           levels = c("18-30", "31-45", "46-60", ">61"))


#select(-OrderDate, 
#         -CustomerBirthDate, 
#         -ID, 
#         -OrderID, 
#         -CustomerID,
#         -PurchasePrice,
#         -DiscountPct,
#         -MSRP,
#         -ProductCost,
#         -CustomerState)
```

[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Portfolio",
    "section": "",
    "text": "Does Temperature Kill Parasites Faster? Yes!\n\n\n\n\n\n\n\nreveal.js\n\n\nR\n\n\npresentation\n\n\ninformative\n\n\nsurvival analysis\n\n\n\n\n\n\n\n\n\n\n\nFeb 27, 2023\n\n\nBrian Cervantes Alvarez\n\n\n\n\n\n\n  \n\n\n\n\nDo You Like Stretching? I would Reconsider!\n\n\n\n\n\n\n\nR\n\n\ninformative\n\n\ninteractive\n\n\nplotly\n\n\n\n\n\n\n\n\n\n\n\nFeb 24, 2023\n\n\nBrian Cervantes Alvarez\n\n\n\n\n\n\n  \n\n\n\n\nRating Pinot Wines: Is More Expensive Better?\n\n\n\n\n\n\n\nR\n\n\ninformative\n\n\ninteractive\n\n\ndatatables\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 20, 2023\n\n\nBrian Cervantes Alvarez\n\n\n\n\n\n\n  \n\n\n\n\nHealthcare Spending Is Only Getting Worse\n\n\n\n\n\n\n\nR\n\n\nlinear regression\n\n\nstats\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nDec 12, 2022\n\n\nBrian Cervantes Alvarez\n\n\n\n\n\n\n  \n\n\n\n\nPokédex Database\n\n\n\n\n\n\n\npostgreSQL\n\n\ndatabase\n\n\npresentation\n\n\nR\n\n\nsql\n\n\n\n\n\n\n\n\n\n\n\nDec 5, 2022\n\n\nBrian Cervantes Alvarez\n\n\n\n\n\n\n  \n\n\n\n\nResources for Prospective College Students\n\n\n\n\n\n\n\nR\n\n\ninteractive\n\n\ninformative\n\n\nshiny\n\n\n\n\n\n\n\n\n\n\n\nDec 2, 2022\n\n\nBrian Cervantes Alvarez, Corey Cassell\n\n\n\n\n\n\n  \n\n\n\n\nU.S. Medical Insurance Costs\n\n\n\n\n\n\n\npython\n\n\nhealthcare\n\n\nanalysis\n\n\nstats\n\n\n\n\n\n\n\n\n\n\n\nJul 14, 2022\n\n\nBrian Cervantes Alvarez\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Background\nI come from a background in retail, where I have gained valuable experience in customer service, sales, and inventory management. However, I have always been fascinated by the power of data and its potential to inform business decisions and drive growth. As a result, I have pursued coursework in data science and gained proficiency in programming languages such as Python, R, and SQL. I have also completed projects that involved data cleaning, exploratory data analysis, and predictive modeling. My experience in retail has taught me the importance of understanding customer behavior and market trends, and I believe that these insights can be enhanced through the use of data-driven approaches. I am excited to apply my skills and knowledge to a career in data science and contribute to an organization that values innovation and data-driven decision-making.\n\n\nGoal\nMy goal as a Data Scientist is to leverage my skills and knowledge to contribute to a dynamic organization that values innovation and data-driven decision-making. I am seeking a challenging role where I can apply my expertise in statistical analysis, machine learning, and data visualization to solve complex problems and drive business growth. Through my academic coursework and hands-on experience, I have developed a strong foundation in programming languages such as Python, R, and SQL, as well as tools and frameworks like Tableau, Pandas, and Scikit-learn. I am excited to continue building my skills and learning from experienced professionals in the industry.\n\n\nEducation\nWillamette University, Salem, OR | M.S. in Data Science | Aug 2022 - Aug 2023\nLinfield University, McMinnville, OR | B.A. in Mathematics | Aug 2018 - May 2022\n\n\nProfessional Experience\nThe North Face, a VF Company | Retail Specialist | Oct 2019 - June 2021, Oct 2022 - present\n\nCustomer service: As a retail worker at The North Face, I have developed strong customer service skills, including active listening, problem-solving, and conflict resolution. I am able to provide product recommendations, answer questions about features and benefits, and ensure that customers have a positive experience in the store.\nSales: I am proficient in sales techniques, including suggestive selling, upselling, and cross-selling. I understand how to build rapport with customers and how to close a sale effectively. I am also comfortable with point-of-sale systems and can process transactions accurately and efficiently.\nProduct knowledge: I have in-depth knowledge of The North Face’s products, including their features, benefits, and intended uses. I am able to explain technical details, such as materials and construction, to customers in a clear and concise manner.\nInventory management: I am experienced in managing inventory, including receiving, organizing, and stocking products. I am able to track inventory levels and identify when reorders are necessary. I am also skilled in visual merchandising and can arrange products in an aesthetically pleasing and organized manner.\nTeamwork: I am able to work collaboratively with other team members to achieve common goals. I am comfortable with delegating tasks, taking direction from others, and providing constructive feedback. I am also able to work independently and take initiative when necessary.\nCommunication: I have excellent verbal and written communication skills. I am able to communicate effectively with customers, team members, and management. I am also comfortable with public speaking and can present information to groups in a clear and engaging manner.\n\n\n\nLanguages\n\nI have a deep understanding of the cultural nuances of both English and Spanish-speaking communities. I am able to navigate cultural differences with sensitivity and respect.\nI have basic verbal and written communication skills in French. I am able to introduce myself, ask and answer basic questions, and engage in simple conversations. I am also able to write simple sentences and paragraphs in French."
  },
  {
    "objectID": "posts/US_HealthIns_Costs/index.html",
    "href": "posts/US_HealthIns_Costs/index.html",
    "title": "U.S. Medical Insurance Costs",
    "section": "",
    "text": "The focal point of this project pertains to the medical insurance industry. I showcase my proficiency in creating compelling visualizations and conducting statistical analyses on a refined data set. Prior to delving into the data set, I formulated several key questions to guide my investigation. These inquiries included identifying the principal driver of heightened insurance costs, evaluating the variables that contribute to rising or falling medical insurance expenses, and identifying the optimal individual profile that minimizes medical insurance costs.\nOf particular interest in this study was the analysis of smoking habits as a variable that may have a significant impact on medical insurance expenses. Moreover, a detailed exploration of the disparities in insurance costs between male and female individuals, both smokers and non-smokers, was conducted.\nTo accomplish these objectives, advanced analytical tools and methodologies were utilized. Rigorous data cleaning and wrangling were carried out to ensure the accuracy and integrity of the data. Subsequently, advanced statistical techniques such as linear regression and hypothesis testing were utilized to extract meaningful insights from the data.\nUltimately, this project provides valuable insights into the medical insurance industry and serves as a testament to the power of data analytics in unlocking actionable insights that can drive informed decision-making.\nIf you wish to skip towards the results portion, feel free to scroll down and have a quick read! Interesting results were found.\n\n\n\n\n   age     sex     bmi  children smoker     region      charges\n0   19  female  27.900         0    yes  southwest  16884.92400\n1   18    male  33.770         1     no  southeast   1725.55230\n2   28    male  33.000         3     no  southeast   4449.46200\n3   33    male  22.705         0     no  northwest  21984.47061\n4   32    male  28.880         0     no  northwest   3866.85520\n\n\n\n\n\n\nWe want to know what influences the cost of insurance. What causes an individual to pay more for their insurance? We can infer that being a smoker will drastically increase their out of pocket medical insurance expenses.\nI take a look into how many smokers we have in this data set. Then, I take a quick look into the smokers’ distribution of charges and show a boxplot to visualize the insurance cost quartiles. Next, I dive into using some statistics such as finding the min, max, mean, median, etc. I follow up by seperating male and female smokers and seeing if there’s a drastic change in their expenses.\n\n\n\nSmoker Count: 274\nNonsmoker Count: 1064\n\n\n\n\n\n\n<Figure size 672x480 with 0 Axes>\n\n\n\n\n\nThe interquartile range is $20,125.33. Very high spread from the first and third interquartiles.\nNow, notice that we have a bimodal distribution. This means that there is a variable in the data set that is drastically affecting the insurance cost. Since there is two “humps” we must identify the component that causes a further jump in insurance costs for those who smoke.\nWhat could cause this? - Region? - Bmi? - Sex? - Children? - Age?\n\n\n\n\n\n<Figure size 672x480 with 0 Axes>\n\n\n\n\n\nSummary Stats: - Mean: $32,050.23 - Median: $34,456.35 - Max: $63,770.43 - Min: $12,829.46 - Standard Deviation: $11,520.47 - Variance: 132721153.14\nGiven the distribution, we can say that the mean represents the true average insurance cost for smokers.\n\n\n\nI chose to seperate male and female smokers to see if there was a noticable difference in cost. Notice in the graphs below, that we can easily identify the culprit for the bimodal distribution. The BMI drastically influences the insurance cost when it is greater than or equal to 30 (the obese rating starts at 30 forward). This means that being obese AND being a smoker can sharply increase your medical insurance cost.\nNote: As Age slowly increases, the insurance cost also slowly increases. So, there is a gradual increase in insurance cost as you age. That is common sense since as one ages, one develops more health issues as they near death.\n\n\n\nGraph One: Cost Distribution - Bimodal Distribution is again present. - Two clusters of cost are due to an underlying variable.\nGraph Two: Barplot of Average Cost per Child - No clear trend. - Only valuable note is that having 4 children seems to have an overall lower average insurance cost.\nGraph Three: Scatterplot of Cost vs BMI with Region - There is a visable linear relationship between BMI and Cost. - There are two clusters of individuals but follows the linear relationship. - At >=30 BMI, there is a clear signifcant increase in insurance cost for male smokers. - Note: a BMI of 30 or implies that the individual is “obese” (though, BMI is not necessarily a good measurement–see results). - No trends with the region.\nGraph Four: Scatterplot of Cost vs Age with Children - There is a linear trend, but split into two linear clusters. - As found earlier, this is most likely due to BMI differences in the indivduals. - Overtime, an individual’s insurance cost will increase as expected.\nGraph Five: Barplot of Average Cost per Region - No valuable insights can be drawn.\nGraph Six: Boxplot of Male Smoker Insurance Cost - Noteworthy to see the spread of male smokers’ insurance cost.\n\n\n\n\n\n<Figure size 672x480 with 0 Axes>\n\n\n\n\n\nAs mentioned above, the reason why the cost distribution had two clusters was due to the difference in BMI in each male smoker. Male smokers with a BMI >= 30 will that their expense increase by approximately 47%.\n\n\nText(0, 0.5, 'Insurance Costs (USD)')\n\n\n\n\n\n\n\n\nGraph One: Cost Distribution - Bimodal Distribution is again present. - Two clusters of cost are due to an underlying variable.\nGraph Two: Barplot of Average Cost per Child - No clear trend. - Only valuable note is that having 5 children seems to have an overall lower average insurance cost.\nGraph Three: Scatterplot of Cost vs BMI with Region - There is a visable linear relationship between BMI and Cost - There are two clusters of individuals but follows the linear relationship. - At >=30 BMI, there is a clear signifcant increase in insurance cost for female smokers. - Note: a BMI of 30 or implies that the individual is “obese” (though, BMI is not necessarily a good measurement–see results). - No trends with the region.\nGraph Four: Scatterplot of Cost vs Age with Children - There is a linear trend, but split into two linear clusters. - As found earlier, this is most likely due to BMI differences in the indivduals. - Overtime, an individual’s insurance cost will increase as expected.\nGraph Five: Barplot of Average Cost per Region - No valuable insights can be drawn.\nGraph Six: Boxplot of Female Smoker Insurance Cost - Noteworthy to see the spread of female smokers’ insurance cost.\nGiven that the Insurane Cost vs BMI is essentially the same as male smokers, the stated results will apply here.\n\n\n\n\n\n<Figure size 672x480 with 0 Axes>\n\n\n\n\n\nNoteworthy mention: - Male smokers pay approximately 1.34% more than their female counterparts when their BMI less than 30. - Male smokers pay approximately 1.42% less than their female counterparts when their BMI greater than or equal to 30.\n\n\n\n\n\n<function matplotlib.pyplot.clf()>\n\n\n\n\n\nThe interquartile range is $7,378.07. Spread is minimal from the first and third interquartiles.\nNow, notice that we have a right-skewed distribution.\nWhat could cause this? - Region? - Bmi? - Sex? - Children? - Age?\nKeep in mind, there is a chance that we may not be able to determine the cause of those outliers.\n\n\n7378.07\n\n\n\n\n\n<Figure size 672x480 with 0 Axes>\n\n\n\n\n\n\nNow let’s look at the nonsmokers.\nSummary Stats: - Mean: $8,434.27 - Median: $7,345.41 - Max: $39,910.61 - Min: $1,121.87 - Standard Deviation: $5,990.96 - Variance: 35891656\n\n\nGraph One: Cost Distribution - Right-skewed distribution is again present. - Knowing this, we should go with the median as the most appropriate statistic instead of the mean.\nGraph Two: Barplot of Average Cost per Child - There seems to be a trend that having more children will lead to higher average insurance costs. - Given the information from the smokers, when an individual has 5 children or more, their insurance costs drops signifcantly. - However, the lowest average comes from having no children at all.\nGraph Three: Scatterplot of Cost vs BMI with Region - There is no correlation between cost and BMI of nonsmokers. - This is an interesting finding. - No trends with the region.\nGraph Four: Scatterplot of Cost vs Age with Children - Strong linear relationship between insurance cost and age. - A secondary trend is shown with the number of children. - The less children, the insurance cost is on the lower end of the linear relationship. - The more children, the insurance cost is on the higher end of the linear relationship - The outliers do not follow the trend line.\nGraph Five: Barplot of Average Cost per Region - No valuable insights can be drawn. - Some regions are simply cheaper than others.\nGraph Six: Boxplot of Male Smoker Insurance Cost - Noteworthy to see the spread of male smokers’ insurance cost.\n\n\n\n\n\n<Figure size 672x480 with 0 Axes>\n\n\n\n\n\n\n\n<Figure size 672x480 with 0 Axes>\n\n\n\n\n\nGraph One: Cost Distribution - Right-skewed distribution is again present. - Knowing this, we should go with the median as the most appropriate statistic instead of the mean.\nGraph Two: Barplot of Average Cost per Child - Similar to the male nonsmokers, there seems to be a trend that having more children will result in higher average insurance costs. - Given the information from the smokers, when an individual has 5 children or more, their insurance costs drops on average. - However, the lowest average comes from having no children at all.\nGraph Three: Scatterplot of Cost vs BMI with Region - Again, there is no correlation between cost and BMI of nonsmokers. - No trends with the region.\nGraph Four: Scatterplot of Cost vs Age with Children - Strong linear relationship between insurance cost and age. - A secondary trend is shown with the number of children. - The less children, the insurance cost is on the lower end of the linear relationship. - The more children, the insurance cost is on the higher end of the linear relationship - The outliers do not follow the trend line.\nGraph Five: Barplot of Average Cost per Region - There is a slight trend of region importance. - The northeast is more expensive on average than the southwest.\nGraph Six: Boxplot of Male Smoker Insurance Cost - Noteworthy to see the spread of male smokers’ insurance cost.\n\n\n\n\n\n<Figure size 672x480 with 0 Axes>"
  },
  {
    "objectID": "posts/FancyTables/index.html",
    "href": "posts/FancyTables/index.html",
    "title": "Rating Pinot Wines: Is Pricier Better?",
    "section": "",
    "text": "Exploring different methods of creating visually satisfying data tables. Admit it, we do not like the tradition excel format: too ugly to understand.\n\n\n\n\n\n\n\nDT Table Code\nds_starter <- ds %>% \n  mutate(province = as.factor(province),\n         price = price,\n         thetaPointMean = mean(points),\n         thetaPriceMean = mean(price))\n\nds_starter %>% \n    arrange(province, year) %>%\n  select(Province = province, \n         Year = year, \n         Price = price, \n         Points = points, \n         Description = description) %>%\n  datatable(., \n            filter = \"bottom\", \n            extensions = 'Buttons', \n            options = list(dom = 'Bfrtip',\n                           buttons = c('copy', 'csv', 'excel'), \n                           initComplete = JS(\"function(settings, json) {\",\n                                             \"$(this.api().table().header()).css({'background-color': '#131F4F', 'color': '#fff'});\",\n                                             \"}\")))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGT Table Code\nfancyTbl <- ds_summary %>%\n  gt() %>%\n# format the numeric output to 3 digit rounding  \n  fmt_number(columns = c(pointsMean, pointsSD, priceMean, priceSD),\n             decimals = 3) %>%\n# create nice labels for a few ugly variable names\n  cols_label(province = \"Province\",\n             pointsMean = \"Avg. Points\",\n             pointsSD = \"Std. Dev. Points\",\n             priceMean = \"Avg. Price\",\n             priceSD = \"Std. Dev. Price\",\n             points = \"Points Trend\",\n             price = \"Price Trend\",) %>%\n# Plot the sparklines from the list column\n  gt_plt_sparkline(points, \n                   type=\"ref_median\", \n                   same_limit = TRUE\n                   ) %>%\n  gt_plt_sparkline(price, \n                   type=\"ref_median\", \n                   same_limit = TRUE\n                   ) %>%\n# use the guardian's table theme\n  gt_theme_guardian() %>% \n# give hulk coloring to the Mean Human Rights Score\n  gt_hulk_col_numeric(pointsMean) %>%\n  gt_hulk_col_numeric(priceMean) %>%\n# create a header and subheader\n  tab_header(title=\"Province Pinot Wine Summary\", subtitle = \"Source: Dr. Hendrick\") %>%\n# attach excel file\n  tab_source_note(excel_file_attachment)\n# save the original as an image\n#gtsave(fancyTbl, \"table.png\")\n# show the table themed in accordance with the page\nfancyTbl\n\n\n\n\n\n\n  \n    \n      Province Pinot Wine Summary\n    \n    \n      Source: Dr. Hendrick\n    \n  \n  \n    \n      Province\n      Avg. Points\n      Std. Dev. Points\n      Avg. Price\n      Std. Dev. Price\n      Points Trend\n      Price Trend\n    \n  \n  \n    Burgundy\n90.438\n2.989\n98.035\n132.856\n          89.0\n          83.0\n    California\n90.517\n2.831\n47.465\n18.553\n          91.0\n          34.0\n    Casablanca_Valley\n86.282\n2.428\n21.107\n11.953\n          87.0\n          30.0\n    Marlborough\n87.550\n2.245\n27.668\n13.833\n          85.0\n          25.0\n    New_York\n87.748\n2.268\n25.679\n9.565\n          88.0\n          35.0\n    Oregon\n89.489\n2.663\n44.856\n20.209\n          90.0\n          22.0\n  \n  \n    \n      \n   Download Excel"
  },
  {
    "objectID": "posts/US_HealthCare_Spending/index.html#abstract",
    "href": "posts/US_HealthCare_Spending/index.html#abstract",
    "title": "Healthcare Spending Is Only Getting Worse",
    "section": "ABSTRACT",
    "text": "ABSTRACT\nU.S. Healthcare costs are increasing in every category since 1980. There are an unfiltered number of reasons for the rise of these costs. From population increase to doctor’s wages, they are but a few examples of the unforgiving healthcare spending increases that are observed in a yearly basis. This report examines the expenditure trends from 1980 to 2005 and up to 2014. The results show that each sector in the United States is experiencing an unprecedented increase in health care costs. Hence, the findings revealed in this report serve to provide context behind the United States’ status as one the most expensive health care nations in the world."
  },
  {
    "objectID": "posts/US_HealthCare_Spending/index.html#introduction",
    "href": "posts/US_HealthCare_Spending/index.html#introduction",
    "title": "Healthcare Spending Is Only Getting Worse",
    "section": "INTRODUCTION",
    "text": "INTRODUCTION\nHealthcare is a vital component to our lives. Without it, we cannot get the necessary help to live happy lives. Or worse, we could not live long enough to enjoy it. However, Healthcare spending continues to skyrocket in a year to year basis. This report reveals the frightening truth about the healthcare spending and visualizes each component. From the overall spending nationally, to showing each category and their individual trends, the spending remains increasingly constant."
  },
  {
    "objectID": "posts/US_HealthCare_Spending/index.html#background",
    "href": "posts/US_HealthCare_Spending/index.html#background",
    "title": "Healthcare Spending Is Only Getting Worse",
    "section": "BACKGROUND",
    "text": "BACKGROUND\nNow, the data set that was used for this report is called US Healthcare Spending Per Capita (source: Kaggle). The format of this data set was quite tricky. Instead of being in the long format, with few columns and lengthy rows, it was in the wide format, lots of columns and very few rows. Specifically, the years were in the format, “Y####” which made it very difficult to do any sort of analysis at first. Though, with some pivoting and string manipulation, the updated data set was ready to do some quirky analysis. The full step process is coming up next."
  },
  {
    "objectID": "posts/US_HealthCare_Spending/index.html#methodology",
    "href": "posts/US_HealthCare_Spending/index.html#methodology",
    "title": "Healthcare Spending Is Only Getting Worse",
    "section": "METHODOLOGY",
    "text": "METHODOLOGY\nBefore jumping into the data, first start with seeing whether it is “wide” or “long”. Check out the number of rows and columns to allow some room to do some data wrangling.\n\n\n# A tibble: 5 × 42\n   Code Item    Group Regio…¹ Regio…² State…³  Y1980  Y1981  Y1982  Y1983  Y1984\n  <dbl> <chr>   <chr>   <dbl> <chr>   <chr>    <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n1     1 Person… Unit…       0 United… <NA>    216977 251789 283073 311677 341645\n2     1 Person… Regi…       1 New En… <NA>     12960  14845  16759  18429  20253\n3     1 Person… Regi…       2 Mideast <NA>     43479  49604  55406  61165  68154\n4     1 Person… Regi…       3 Great … <NA>     40658  46668  51440  55967  60776\n5     1 Person… Regi…       4 Plains  <NA>     16980  19682  21919  23940  25684\n# … with 31 more variables: Y1985 <dbl>, Y1986 <dbl>, Y1987 <dbl>, Y1988 <dbl>,\n#   Y1989 <dbl>, Y1990 <dbl>, Y1991 <dbl>, Y1992 <dbl>, Y1993 <dbl>,\n#   Y1994 <dbl>, Y1995 <dbl>, Y1996 <dbl>, Y1997 <dbl>, Y1998 <dbl>,\n#   Y1999 <dbl>, Y2000 <dbl>, Y2001 <dbl>, Y2002 <dbl>, Y2003 <dbl>,\n#   Y2004 <dbl>, Y2005 <dbl>, Y2006 <dbl>, Y2007 <dbl>, Y2008 <dbl>,\n#   Y2009 <dbl>, Y2010 <dbl>, Y2011 <dbl>, Y2012 <dbl>, Y2013 <dbl>,\n#   Y2014 <dbl>, Average_Annual_Percent_Growth <dbl>, and abbreviated …\n\n\n [1] \"Code\"                          \"Item\"                         \n [3] \"Group\"                         \"Region_Number\"                \n [5] \"Region_Name\"                   \"State_Name\"                   \n [7] \"Y1980\"                         \"Y1981\"                        \n [9] \"Y1982\"                         \"Y1983\"                        \n[11] \"Y1984\"                         \"Y1985\"                        \n[13] \"Y1986\"                         \"Y1987\"                        \n[15] \"Y1988\"                         \"Y1989\"                        \n[17] \"Y1990\"                         \"Y1991\"                        \n[19] \"Y1992\"                         \"Y1993\"                        \n[21] \"Y1994\"                         \"Y1995\"                        \n[23] \"Y1996\"                         \"Y1997\"                        \n[25] \"Y1998\"                         \"Y1999\"                        \n[27] \"Y2000\"                         \"Y2001\"                        \n[29] \"Y2002\"                         \"Y2003\"                        \n[31] \"Y2004\"                         \"Y2005\"                        \n[33] \"Y2006\"                         \"Y2007\"                        \n[35] \"Y2008\"                         \"Y2009\"                        \n[37] \"Y2010\"                         \"Y2011\"                        \n[39] \"Y2012\"                         \"Y2013\"                        \n[41] \"Y2014\"                         \"Average_Annual_Percent_Growth\"\n\n\nAs explained earlier, the data set was evidently in the wide format. So, using the “pivot_longer” function with the “tidyverse” package, the years columns were placed into one column called “Year” with their values in the another column called “Cost”. I used the “gsub” function to fix up my Year column and factored a few columns for later use.\n\n\n# A tibble: 6 × 5\n  Item                 Region_Name   State_Name  Year   Cost\n  <fct>                <fct>         <fct>      <dbl>  <dbl>\n1 Personal Health Care United States <NA>        1980 216977\n2 Personal Health Care United States <NA>        1981 251789\n3 Personal Health Care United States <NA>        1982 283073\n4 Personal Health Care United States <NA>        1983 311677\n5 Personal Health Care United States <NA>        1984 341645\n6 Personal Health Care United States <NA>        1985 376376\n\n\n\nHealth Care Costs Have Increased\nDiving straight into the first visual. It appears very clearly that Healthcare spending is in an upward trend and does not appear to slow down. The graph was filter from the years 1980 to 2005 to highlight this era of healthcare costs.\n\n\n\n\n\n\n\nPersonal, Hospital and Physician & Clinical Care Are The Dominate Spending Categories\nYikes. Personal health care went from about $10K to nearly $80K in that short time span. Hospital and Clinical Care are heavy hitters for spending. Though this graph shows the same trend for each category. Not very pleasant information.\n\n\n\n\n\n\n\nEach Region Is Trending The Same\nTerrible news, each region has not stopped increasing spending. Their trend lines all appear to be similar and proportionally alike to one and another. The highlights are that the Mideast is the most expensive and the Rocky Mountains is the cheapest. Note, this was looking at the spending up to 2005. Maybe things will change by 2014.\n\n\n\n\n\n\n\nThe Trends Remain. Healthcare Spending Continues To Rise In Every Region In The U.S.\nIn the bar chart, you can distinguish more clearly each region and their overall spending. What stands out the most is that the Plains, New England and the Rocky Mountains are one of the lowest in terms of medical funding. In some cases, they are 1/3 the cost of the most expensive regions.\n\n\n\n\n\n\n\nThe Far West Ranks 3rd In Healthcare Spending\nFor 2014, that is quite the jump. It can be assumed that all those states are heavy hitters in terms of spending, but that is proven quite wrong in the next graphic.\n\n\n\n\n\n[1] \"$21.81M\"\n[1] \"$21.81M\"\n\n\n\n\nOregon Ranks 3rd, But Don’t Be Fooled!\nLook, California takes the #1 spot in spending. You cannot deny the underlying reasons behind that, such as their ridicously population size. While this report did not look into it, you would probably push the Far West region closer to the Plains or New England in terms of spending.\n\n\n\n\n\n[1] \"$1.41M\"  \"$53.64M\" \"$1.9M\"   \"$3.41M\"  \"$5.81M\"  \"$10.16M\"\n[1] \"$1.41M\"  \"$53.64M\" \"$1.9M\"   \"$3.41M\"  \"$5.81M\"  \"$10.16M\"\n[1] \"$5.81M\"\n[1] \"$5.81M\"\n\n\n\n\nA Linear Fit Is Not The Right Model For This Data\nRight off the bat, the model appears to have an adjusted R-Squared value of 0.8572. That looks wondeful, right? No! This model is not accurate at all and is highly discouraged. It becomes clear that their is no correlation between Cost and Region_Name per Year. While not shown, this was true for the filtered data set that went up from 1980 to 2014. The residual plots speak for themselves. The Residuals vs Fitted was showing clear signs of being a quadratic fit instead of a linear one. The Q-Q was short of linear but had a number of curves along the fitted line. The scale location evidently showed that this model was simple not the correct fit for this data.\n\n\nA Linear Fit Is Not The Right Model For This Data\nRight off the bat, the model appears to have an adjusted R-Squared value of 0.8572. That looks wondeful, right? No! This model is not accurate at all and is highly discouraged. It becomes clear that their is no correlation between Cost and Region_Name per Year. While not shown, this was true for the filtered data set that went up from 1980 to 2014. The residual plots speak for themselves. The Residuals vs Fitted was showing clear signs of being a quadratic fit instead of a linear one. The Q-Q was short of linear but had a number of curves along the fitted line. The scale location evidently showed that this model was simple not the correct fit for this data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n      1 \n11072.4 \n\n\n\nCall:\nlm(formula = Cost ~ Region_Name + Year, data = regionHealthCareSince2005)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2683.8  -782.9  -279.8   597.7  4139.3 \n\nCoefficients:\n                             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                -680650.41   24479.29 -27.805  < 2e-16 ***\nRegion_NameGreat Lakes        1438.65     368.55   3.904 0.000130 ***\nRegion_NameMideast            1657.50     368.55   4.497 1.17e-05 ***\nRegion_NameNew England       -3909.68     368.55 -10.608  < 2e-16 ***\nRegion_NamePlains            -3830.75     368.55 -10.394  < 2e-16 ***\nRegion_NameRocky Mountains   -5106.26     368.55 -13.855  < 2e-16 ***\nRegion_NameSoutheast         -1231.18     368.55  -3.341 0.000998 ***\nRegion_NameSouthwest          -849.93     368.55  -2.306 0.022133 *  \nYear                           344.83      12.29  28.069  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1329 on 199 degrees of freedom\nMultiple R-squared:   0.88, Adjusted R-squared:  0.8752 \nF-statistic: 182.4 on 8 and 199 DF,  p-value: < 2.2e-16\n\n\n             Df    Sum Sq   Mean Sq F value Pr(>F)    \nRegion_Name   7 1.185e+09 1.693e+08    95.9 <2e-16 ***\nYear          1 1.391e+09 1.391e+09   787.9 <2e-16 ***\nResiduals   199 3.514e+08 1.766e+06                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nWas there A Significant Difference In The Means Of Each Region?\nI wished to explore if it was statistically significant on where each region’s mean over the years mattered. I actually started off using a LeveneTest to see if the variance (the spread of the spending for each region) was important. Given both tests yielded an extremely small p-value, it is clear that there are 3 regions that have a completely different variance than the other regions. I was not done there, I now wanted to confirm this with the TukeyHsd test to see if their means differed as a result. Yes, their means differed as expected from the LeveneTest. To make clear, New England, Plains and Rocky Mountains spent much lower on average. Despite that fact, they are following the trend of growth with an 18% since 2005.\nI wished to explore if it was statistically significant on where each region’s mean over the years mattered. I actually started off using a LeveneTest to see if the variance (the spread of the spending for each region) was important. Given both tests yielded an extremely small p-value, it is clear that there are 3 regions that have a completely different variance than the other regions. I was not done there, I now wanted to confirm this with the TukeyHsd test to see if their means differed as a result. Yes, their means differed as expected from the LeveneTest. To make clear, New England, Plains and Rocky Mountains spent much lower on average. Despite that fact, they are following the trend of growth with an 18% since 2005.\n\n\n[1] \"The Average Spending In The Expensive Regions since 2005 = $5333.29\"\n\n\n[1] \"The Average Spending In The Expensive Regions since 2014= $7724.45\"\n\n\n[1] \"Difference: +$2391.16 | Percentage Increase: +18.31%\"\n\n\n[1] \"The Average Spending In The Cheap Regions since 2005 = $2173.22\"\n\n\n[1] \"The Average Spending In The Cheap Regions since 2014= $3142.21\"\n\n\n[1] \"Difference: +$968.99 | Percentage Increase: 18.23%\"\n\n\nLevene's Test for Homogeneity of Variance (center = mean)\n       Df F value    Pr(>F)    \ngroup   7   12.03 8.727e-13 ***\n      200                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value    Pr(>F)    \ngroup   7  11.462 3.292e-12 ***\n      200                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLevene's Test for Homogeneity of Variance (center = mean)\n       Df F value    Pr(>F)    \ngroup   7  19.546 < 2.2e-16 ***\n      272                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value    Pr(>F)    \ngroup   7  12.828 3.075e-14 ***\n      272                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n             Df    Sum Sq   Mean Sq F value Pr(>F)    \nRegion_Name   7 1.185e+09 169337440   19.43 <2e-16 ***\nResiduals   200 1.743e+09   8712933                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = Cost ~ Region_Name, data = regionHealthCareSince2005)\n\n$Region_Name\n                                   diff         lwr           upr     p adj\nGreat Lakes-Far West         1438.64777 -1069.19906  3946.4945990 0.6495584\nMideast-Far West             1657.50100  -850.34583  4165.3478291 0.4679930\nNew England-Far West        -3909.68132 -6417.52815 -1401.8344885 0.0000930\nPlains-Far West             -3830.75287 -6338.59970 -1322.9060420 0.0001417\nRocky Mountains-Far West    -5106.25783 -7614.10466 -2598.4109954 0.0000001\nSoutheast-Far West          -1231.18113 -3739.02796  1276.6657036 0.8046614\nSouthwest-Far West           -849.92577 -3357.77260  1657.9210559 0.9679983\nMideast-Great Lakes           218.85323 -2288.99360  2726.7000602 0.9999950\nNew England-Great Lakes     -5348.32909 -7856.17592 -2840.4822574 0.0000000\nPlains-Great Lakes          -5269.40064 -7777.24747 -2761.5538109 0.0000000\nRocky Mountains-Great Lakes -6544.90559 -9052.75242 -4037.0587643 0.0000000\nSoutheast-Great Lakes       -2669.82890 -5177.67573  -161.9820653 0.0279871\nSouthwest-Great Lakes       -2288.57354 -4796.42037   219.2732870 0.1019616\nNew England-Mideast         -5567.18232 -8075.02915 -3059.3354875 0.0000000\nPlains-Mideast              -5488.25387 -7996.10070 -2980.4070410 0.0000000\nRocky Mountains-Mideast     -6763.75882 -9271.60565 -4255.9119944 0.0000000\nSoutheast-Mideast           -2888.68213 -5396.52896  -380.8352954 0.0119419\nSouthwest-Mideast           -2507.42677 -5015.27360     0.4200569 0.0500724\nPlains-New England             78.92845 -2428.91838  2586.7752767 1.0000000\nRocky Mountains-New England -1196.57651 -3704.42334  1311.2703233 0.8267302\nSoutheast-New England        2678.50019   170.65336  5186.3470223 0.0270977\nSouthwest-New England        3059.75554   551.90871  5567.6023746 0.0058329\nRocky Mountains-Plains      -1275.50495 -3783.35178  1232.3418768 0.7745369\nSoutheast-Plains             2599.57175    91.72492  5107.4185757 0.0361922\nSouthwest-Plains             2980.82710   472.98027  5488.6739280 0.0081616\nSoutheast-Rocky Mountains    3875.07670  1367.22987  6382.9235291 0.0001119\nSouthwest-Rocky Mountains    4256.33205  1748.48522  6764.1788814 0.0000135\nSouthwest-Southeast           381.25535 -2126.59148  2889.1021825 0.9997829"
  },
  {
    "objectID": "posts/US_HealthCare_Spending/index.html#results",
    "href": "posts/US_HealthCare_Spending/index.html#results",
    "title": "Healthcare Spending Is Only Getting Worse",
    "section": "RESULTS",
    "text": "RESULTS\nU.S. Healthcare costs have more than quintupled from 1980 to 2014. There are trends throughout each region that show no clear indication of healthcare spending going down. While some regions are not as expensive as others, they are still growing at the same pace nationally. Following the trend, personal health care spending averaged approximately $10,000 in 1980, but has substantially increased to nearly $80,000 in 2014. The top 3 most expensive regions as of 2014 are the Mideast, Great Lakes, and Far West. The top 3 least cheapest regions as of 2014 are the Rocky Mountains, New England, and Plains. In the Far West region, Oregon ranks 3rd in being the most expensive State in the region."
  },
  {
    "objectID": "posts/US_HealthCare_Spending/index.html#conclusion",
    "href": "posts/US_HealthCare_Spending/index.html#conclusion",
    "title": "Healthcare Spending Is Only Getting Worse",
    "section": "CONCLUSION",
    "text": "CONCLUSION\nThe United States continues to spend more in their healthcare system. Though, in some categories such as Personal Health Care, you could argue that it is becoming increasingly unaffordable. A $70K difference in 35 years is quite off from inflation expectations. Speaking of inflation, this dataset would have had great potential if inflation adjusted values were given. In that sense, a deeper analysis could be made and more insight would have been gained. Now, one could explore this with even more in depth see if there is any statistical significance between each individual state and their spending habits. That is left and open for anyone to undertake in the future."
  },
  {
    "objectID": "posts/CollegeStudent_Debt_Tool/index.html#purpose",
    "href": "posts/CollegeStudent_Debt_Tool/index.html#purpose",
    "title": "Resources for Prospective College Students",
    "section": "Purpose:",
    "text": "Purpose:\nHow can we provide a prospective college student with information regarding their potential income and student debt upon embarking on a career path? To address this issue, we have created an interactive tool. Although it is uncomplicated and subject to enhancement, it has enabled us to delve into interactive visualizations through the utilization of R Shiny."
  },
  {
    "objectID": "posts/CollegeStudent_Debt_Tool/index.html#summary",
    "href": "posts/CollegeStudent_Debt_Tool/index.html#summary",
    "title": "Resources for Prospective College Students",
    "section": "Summary:",
    "text": "Summary:\nThe interactive visualization is comprised of four distinct parts: salary estimator, tuition estimator, debt estimator, and debt calculator. The salary estimator allows prospective students to explore the potential salaries associated with different majors, thereby enabling them to make informed decisions about their future careers. The tuition estimator provides an estimate of the generalized tuition costs associated with pursuing a major in a particular state. The debt estimator calculates the potential four-year degree debt based on the student’s family income, utilizing an average of all students attending each university, and offers insight into the likely debt accumulation over the four years of study. The final tool analyzes the expected length of time a student will remain in debt, based on their chosen major category, and provides a visualization of the projected student debts. Overall, this interactive tool is an invaluable resource for high school students who are considering higher education, offering a comprehensive set of tools to help them make informed decisions about their future."
  },
  {
    "objectID": "posts/CollegeStudent_Debt_Tool/index.html#shiny-interactive-tool",
    "href": "posts/CollegeStudent_Debt_Tool/index.html#shiny-interactive-tool",
    "title": "Resources for Prospective College Students",
    "section": "Shiny Interactive Tool",
    "text": "Shiny Interactive Tool"
  },
  {
    "objectID": "posts/CollegeStudent_Debt_Tool/index.html#setup",
    "href": "posts/CollegeStudent_Debt_Tool/index.html#setup",
    "title": "Resources for Prospective College Students",
    "section": "Setup",
    "text": "Setup\n\n\nSetup + Wrangling\nlibrary(shiny)\nlibrary(tidyverse)\nlibrary(showtext)\nlibrary(ggtext)\nlibrary(RColorBrewer)\nlibrary(rsconnect)\nlibrary(colorspace)\nlibrary(plotly)\nlibrary(shinyWidgets)\nlibrary(scales)\nlibrary(ggplot2)\n\n#read the files in from github\nallAgesDf <- read_csv(\"all-ages.csv\")\ntuition_cost <- read_csv(\"tuition_income.csv\")\ntuition <- read_csv(\"tuition_cost.csv\")\nds4<-read_csv(\"salary_and_stats.csv\")\n\n#Wrangling Salary Potential\nsalary <- allAgesDf %>% \n  dplyr::select(Major, P25th, Median, P75th) %>% \n  pivot_longer(c(P25th, Median, P75th),\n               names_to = \"Percentile_Range\", values_to = \"Salary\") %>%\n  arrange(Major) %>%\n  mutate(Percentile_Range = as.factor(Percentile_Range),\n         Major = as.factor(Major))\n\n#Wrangling Potential Tuition Burden\n\n\ntuition_cost <- tuition_cost %>% \n  filter(year == 2018 & net_cost > 0) %>%\n  arrange(name) %>%\n  mutate(income_lvl = as.factor(income_lvl),\n         name = as.factor(name))\n  \n\ntuition_cost$income_lvl <- recode(tuition_cost$income_lvl, \n                                  \"0 to 30,000\" = \"$0 to $30,000\",\n                                  \"30,001 to 48,000\" = \"$30,001 to $48,000\",\n                                  \"48_001 to 75,000\" = \"$48,001 to $75,000\",\n                                  \"75,001 to 110,000\" = \"$75,001 to $110,000\",\n                                  \"Over 110,000\" = \"Over $110,000\")\nsalary$Percentile_Range <- factor(salary$Percentile_Range, levels = c(\"P25th\", \"Median\", \"P75th\"))\nsalary$Percentile_Range <- recode(salary$Percentile_Range, \n                                  \"P25th\" = \"Early Career\",\n                                  \"Median\" = \"Middle Career\",\n                                  \"P75th\" = \"Late Career\")\nsalary$Major <- str_to_title(salary$Major)\nsalary$Major <- gsub(\"And\", \"and\", salary$Major)\n\n\ndf <- tuition %>% \n  group_by(state, degree_length, type) %>% filter(!is.na(state) & degree_length != \"Other\") %>%\n  summarise(room_expenses = mean(room_and_board, na.rm = TRUE),\n            inStateTotal = mean(in_state_total, na.rm = TRUE),\n            outOfStateTotal = mean(out_of_state_total, na.rm = TRUE))\n\ndf$degree_length <- as.factor(df$degree_length)\ndf$type <- as.factor(df$type)\n\ndf <- df %>% rename(\"Room and Board\" = room_expenses,\n              \"In State Tuition\" = inStateTotal,\n              \"Out of State Tuition\" = outOfStateTotal)\n\n\n\n\nColor Theme\n#vars  \n  title = 25\n  subtitle = 20\n  facet_title = 25\n  axis_title = 18\n  tick_numbers = 13\n  title_color = \"black\"\n  background = \"gainsboro\"\n  plot_background = \"gainsboro\"\n  facet_header_background = \"gainsboro\"\n  line_type = \"solid\"\n\nCoreyPlotTheme <- theme(\n    text = element_text(family = \"Futura\"),\n    #background color of page\n    plot.background = element_rect(fill = background),\n    \n    #graph background and grid\n    panel.background = element_blank(),\n    panel.grid.major = element_line(size = .1, linetype = line_type, colour = \"gainsboro\"), \n    panel.grid.minor = element_line(size = .1, linetype = line_type, colour = \"black\"),\n    \n    #title/font/labels\n    plot.title = element_text(color = title_color, size = title,family = \"Futura\",hjust = 0.5),\n    plot.subtitle = element_text(color = title_color, size = subtitle,family = \"Futura\", hjust = 0.5),\n    #plot.caption = element_textbox_simple(halign = 0, size = tick_numbers, maxwidth = 30,family = \"Futura\"),\n    plot.caption = element_text(color = title_color, face = \"bold\", size = tick_numbers, family = \"Futura\", hjust=0),\n    strip.text = element_text(color = title_color,size = facet_title, family = \"Futura\"),\n    strip.background = element_rect(fill = facet_header_background),\n    \n    #tick marks\n    axis.text = element_text(color = title_color, size = tick_numbers, family = \"Futura\"),\n    axis.title = element_text(color = title_color, size = axis_title, family = \"Futura\"),\n    axis.ticks.x = element_blank(),\n    \n    #legend\n    legend.title = element_text(color = title_color,size =subtitle, family = \"Futura\"),\n    legend.background = element_rect(fill = plot_background),\n    legend.text = element_text(size = tick_numbers, family =\"Futura\" )\n  )"
  },
  {
    "objectID": "posts/CollegeStudent_Debt_Tool/index.html#plot-sidebar-inputs",
    "href": "posts/CollegeStudent_Debt_Tool/index.html#plot-sidebar-inputs",
    "title": "Resources for Prospective College Students",
    "section": "Plot Sidebar Inputs",
    "text": "Plot Sidebar Inputs\n\n\nSalary Estimator Selectors\n#INPUT FOR PLOT 1\n\ninput1 <- inputPanel(\n  selectInput(\"selectInput1\", label = \"Choose your major:\", \n              choices = unique(salary$Major),\n              selected = \"ART HISTORY AND CRITICISM\"),\n  checkboxGroupInput(\"percentile_choice\", label = \"Pick your career level:\", \n                     choices = list(\"Early Career \" = \"Early Career\",\n                                    \"Middle Career \" = \"Middle Career\",\n                                    \"Late Career \" = \"Late Career\"),\n                     selected = c(\"Early Career\", \"Middle Career\", \"Late Career\")),\n)\n\n\n\n\nTuition Estimator Options\n#INPUT FOR PLOT 2\n\ninput2 <- inputPanel(\n  selectInput(\"money\", label = \"Select the type of expense:\",\n              choices = c(\"Room and Board\" = \"Room and Board\",\n                          \"In State Tuition\" = \"In State Tuition\",\n                          \"Out of State Tuition\" = \"Out of State Tuition\"),\n              selected = \"In State Tuition\"),\n  selectInput(\"state\", label = \"Pick your State:\", \n              choices = unique(df$state),\n              selected = \"Oregon\"),\n)\n\n\n\n\nDebt Estimator Levels\n#INPUT FOR PLOT 3\n\ninput3 <- inputPanel(\n  selectInput(\"selectInput2\", \n              label = \"Select your university:\",\n              choices = unique(tuition_cost$name), \n              selected = \"Willamette University\"),\n  checkboxGroupInput(\"checkGroup\", \n                     label = \"Select your household income bracket:\", \n                     choices = list(\"$0 to $30,000\" = \"$0 to $30,000\",\n                                    \"$30,001 to $48,000\" = \"$30,001 to $48,000\",\n                                    \"$48,001 to $75,000\" = \"$48,001 to $75,000\",\n                                    \"$75,001 to $110,000\" = \"$75,001 to $110,000\",\n                                    \"Over $110,000\" = \"Over $110,000\"),\n                               selected = c(\"$0 to $30,000\",\n                                            \"$30,001 to $48,000\",\n                                            \"$48,001 to $75,000\",\n                                            \"$75,001 to $110,000\",\n                                            \"Over $110,000\")),\n)\n\n\n\n\nDebt Calculator Choices\n#INPUT FOR PLOT 4\n\ninput4 <- inputPanel(\n  selectInput(\"major_category\", \n              label = \"Pick a major category:\", \n              choices = unique(ds4$major_category),\n              selected = \"Computers & Mathematics\"),\n)"
  },
  {
    "objectID": "posts/CollegeStudent_Debt_Tool/index.html#plots",
    "href": "posts/CollegeStudent_Debt_Tool/index.html#plots",
    "title": "Resources for Prospective College Students",
    "section": "Plots",
    "text": "Plots\n\n\nSalary Estimator\n#PLOT1\nplot1 <- renderPlot({\n  salary %>% \n    filter((Major %in% input$selectInput1) & (Percentile_Range %in% input$percentile_choice)) %>% \n    ggplot(aes(x = Percentile_Range, y = Salary, fill = Percentile_Range)) +\n      geom_col(width = 0.4, color = \"black\", show.legend = FALSE) +\n      geom_label(aes(y = Salary,\n                     label = print(paste0(\"$\", round(Salary/1000, 2), \"K\"))),\n                 show.legend = FALSE,\n                 size = 7,\n                 family = \"Futura\",\n                 fill = \"white\") +\n      scale_y_continuous(labels = label_number(prefix = \"$\", suffix = \"K\", scale = 1e-3)) +\n      labs(x = NULL,\n           y = NULL,\n           title = paste0(\"Estimated Salary for \", input$selectInput1),\n           caption = \"Source: TuitionTracker.org @ 2018\") + \n      CoreyPlotTheme +\n      scale_fill_brewer(palette = \"PuBuGn\")\n})\n\n\n\n\nTuition Estimator\n#PLOT2\nplot2 <- renderPlot({\n  df %>% filter(state == input$state) %>%\n      ggplot(aes(x = degree_length, y = .data[[input$money]], fill = degree_length)) +\n      geom_col(width = 0.4, color = \"black\", show.legend = FALSE) +\n      facet_wrap(~type) + \n      geom_label(aes(y = .data[[input$money]],\n                     label = print(paste0(\"$\", round(.data[[input$money]]/1000, 2), \"K\"))),\n                 family = \"Oswald\",\n                 size = 7,\n                 show.legend = FALSE,\n                 fill = \"white\") +\n      scale_y_continuous(labels = label_number(prefix = \"$\", suffix = \"K\", scale = 1e-3),\n                         limits = c(0,55000)) +\n      labs(x = NULL,\n           y = NULL,\n           title = paste0(\"Average \", input$money, \" for \", input$state, \" Universities\"),\n           subtitle = \"For Undergraduate Degrees\",\n           caption = \"Source: TuitionTracker.org @ 2018\") + \n      CoreyPlotTheme +\n      scale_fill_brewer(palette = \"PuBuGn\")\n})\n\n\n\n\nDebt Estimator\n#PLOT3\nplot3 <- renderPlot({\n  tuition_cost %>% \n      filter((income_lvl %in% input$checkGroup) & (name %in% input$selectInput2)) %>%\n      ggplot(aes(x = income_lvl, y = net_cost, fill = income_lvl)) +\n      geom_col(color = \"black\", width = 0.4, position = \"dodge\", show.legend = FALSE) +\n      geom_label(aes(y = net_cost,\n                     label = print(paste0(\"$\", round(net_cost/1000, 2), \"K\"))),\n                 family = \"Oswald\",\n                 size = 7,\n                 show.legend = FALSE,\n                 fill = \"white\") +\n      scale_y_continuous(labels = label_number(prefix = \"$\", suffix = \"K\", scale = 1e-3)) +\n      labs(x = NULL,\n           y = NULL,\n           title = paste0(\"Median Student Loan Debt for \", input$selectInput2),\n           subtitle = \"After Completing Their Undergraduate Degree\",\n           caption = \"Source: TuitionTracker.org @ 2018\") +\n      CoreyPlotTheme + \n      scale_fill_brewer(palette = \"PuBuGn\")\n})\n\n\n\n\nDebt Calculator\n#PlOT4\nplot4 <- renderPlot({\n  ds4 %>% \n      filter(major_category == input$major_category) %>% \n      ggplot(aes(perfect_payback_period,reorder(major, perfect_payback_period), fill = perfect_payback_period))+\n      geom_col(show.legend = FALSE) +\n      geom_label(aes(label=paste(round(perfect_payback_period,2),\" yrs.\")), \n                 show.legend = FALSE, \n                 fill = \"white\", \n                 hjust = 1.1) +\n      theme(axis.title.y = element_blank(),\n            axis.text.x = element_blank()) +\n      labs(title = 'How Long Will You Be In Debt?',\n           subtitle = \"Based on Your Major\",\n           x = 'Time to pay off loans')+\n      CoreyPlotTheme +\n      theme(plot.title = element_text(hjust = 0.5)) +\n      scale_fill_continuous_sequential(\"PuBuGn\")\n})"
  },
  {
    "objectID": "posts/CollegeStudent_Debt_Tool/index.html#plots-dont-render-click-interactive-tool",
    "href": "posts/CollegeStudent_Debt_Tool/index.html#plots-dont-render-click-interactive-tool",
    "title": "Resources for Prospective College Students",
    "section": "Plots Don’t Render, Click “Interactive Tool”",
    "text": "Plots Don’t Render, Click “Interactive Tool”\nInteractive Tool\n\n\nCode\n#Salary Estimator\n#input1\n#plot1\n\n#Tuition Estimator\n#input2\n#plot2\n\n#Debt Estimator\n#input3\n#plot3\n\n#Debt Calculator\n#input4\n#plot4"
  },
  {
    "objectID": "posts/Pokemon_Database/index.html",
    "href": "posts/Pokemon_Database/index.html",
    "title": "Pokédex Database",
    "section": "",
    "text": "The main objective of this project was to construct a fully operational Postgresql database in a time frame of fewer than two weeks by employing the Extract, Transform, Load (ETL) methodology. The purpose of this approach was to extract data from various sources, transform it into a format that could be easily integrated into the database, and finally load the transformed data into the database.\nThe process involved several intricate steps, including identifying the relevant data sources, cleansing the extracted data to remove inconsistencies, standardizing the data to a uniform format, and applying data validation and verification techniques to ensure accuracy and completeness. Furthermore, it required careful consideration of the database schema, including the design of tables, relationships between tables, and the use of appropriate data types.\nThe successful implementation of this project was dependent on the utilization of cutting-edge technologies and tools, such as data integration software, data profiling tools, and scripting languages. The result was a functional database that can efficiently store and manage data, making it readily available for analysis, decision-making, and reporting purposes.\n\n\n\nWhat is the best base stat pokemon type? I was intrigued by this question and sought to answer it using some data engineering. First, I used the “Pokémon of Kanto, Johto, and Hoenn Region” dataset to help design and structure my database. Second, I established the database and imported the dataset. Then, I used a few queries and built an new dataset for analysis. Using R, I analyzed and determined that the “Ghost” type was the best base type.\n\n\n\n\n\nDue to time constraints there are some missing tables that would have added more flexiblity to my analysis.\nCREATE TABLE IF NOT EXISTS pokemon (\n    id SMALLINT PRIMARY KEY,\n    identifier TEXT,\n    species_id SMALLINT,\n    height SMALLINT,\n    weight SMALLINT,\n    base_experience SMALLINT,\n    \"order\" SMALLINT,\n    is_default BOOLEAN\n);\n\n\nCREATE TABLE IF NOT EXISTS pokemon_types (\n    pokemon_id SMALLINT,\n    type_id SMALLINT PRIMARY KEY,\n    slot SMALLINT,\n    CONSTRAINT ref_pokemon\n        FOREIGN KEY(pokemon_id)\n            REFERENCES pokemon(id)\n);\n\nCREATE TABLE IF NOT EXISTS pokemon_abilities (\n    pokemon_id SMALLINT,\n    ability_id SMALLINT PRIMARY KEY,\n    is_hidden BOOLEAN,\n    slot SMALLINT,\n    CONSTRAINT ref_pokemon\n        FOREIGN KEY(pokemon_id)\n            REFERENCES pokemon(id)\n);\n\n\nCREATE TABLE IF NOT EXISTS generations (\n    id SMALLINT,\n    main_region_id SMALLINT PRIMARY KEY,\n    identifier CHAR(15) \n);\n\nCREATE TABLE IF NOT EXISTS types (\n    id SMALLINT PRIMARY KEY,\n    identifier CHAR(8),\n    generation_id SMALLINT,\n    damage_class_id SMALLINT,\n    CONSTRAINT ref_pokemon_types\n        FOREIGN KEY(id)\n            REFERENCES pokemon_types(type_id),\n    CONSTRAINT ref_generations \n        FOREIGN KEY(generation_id)\n            REFERENCES generations(main_region_id)\n);\n\nCREATE TABLE IF NOT EXISTS abilities (\n    id SMALLINT,\n    identifier TEXT,\n    generation_id SMALLINT,\n    is_main_series BOOLEAN,\n    CONSTRAINT ref_pokemon_abilities\n        FOREIGN KEY(id)\n            REFERENCES pokemon_abilities(ability_id),\n    CONSTRAINT ref_generations \n        FOREIGN KEY(generation_id)\n            REFERENCES generations(main_region_id)\n);\n\nCREATE TABLE IF NOT EXISTS moves (\n  id SMALLINT,\n  identifier TEXT,\n  generation_id SMALLINT,\n  type_id SMALLINT,\n  power SMALLINT,\n  pp SMALLINT,\n  accuracy SMALLINT,\n  priority SMALLINT,\n  target_id SMALLINT,\n  damage_class_id SMALLINT,\n  effect_id SMALLINT,\n  effect_chance SMALLINT,\n  contest_type_id SMALLINT,\n  contest_effect_id SMALLINT,\n  super_contest_effect_id SMALLINT,\n  CONSTRAINT ref_types\n        UNIQUE(damage_class_id, type_id),\n  CONSTRAINT ref_generations \n        FOREIGN KEY(generation_id)\n            REFERENCES generations(main_region_id),\n  CONSTRAINT ref_types_2\n        FOREIGN KEY(type_id)\n            REFERENCES types(id)\n);\n\n\n\nThis portion of the sql file is for transforming and preparing a csv file for analysis.\nSELECT \n    identifier AS pokemon_name, \n    pokemon_types.type_id,\n    pokemon_abilities.ability_id\nINTO temp1\nFROM pokemon\nLEFT JOIN pokemon_types\nON pokemon.id = pokemon_types.pokemon_id\nLEFT JOIN pokemon_abilities\nON pokemon.id  = pokemon_abilities.pokemon_id;\n\n\nSELECT \n    pokemon_name,\n    types.identifier AS pokemon_type,\n    abilities.identifier AS pokemon_ability,\n    types.generation_id AS gen_id,\n    types.id AS type_id\nINTO temp2\nFROM temp1\nLEFT JOIN types\nON temp1.type_id = types.id\nLEFT JOIN abilities\nON temp1.ability_id = abilities.id;\n\n\nDROP TABLE temp3;\nSELECT \n    pokemon_name,\n    pokemon_type,\n    pokemon_ability,\n    generations.identifier AS pokemon_generation,\n    moves.identifier AS pokemon_move,\n    moves.power AS pokemon_power,\n    moves.accuracy AS pokemon_accuracy,\n    moves.pp AS pokemon_pp\nINTO temp3\nFROM temp2\nLEFT JOIN generations\nON temp2.gen_id = generations.main_region_id\nLEFT JOIN moves\nON temp2.type_id = moves.type_id;\n\nSELECT *\nFROM temp3\nWHERE pokemon_power IS NOT NULL \n    AND pokemon_accuracy IS NOT NULL\nORDER BY pokemon_accuracy, pokemon_power;\n\n\nCOPY temp3\nTO '/Users/Shared/Data_503/Datasets/scuffed_pokedex.csv'\nWITH (FORMAT CSV, HEADER);\n\n\n\nHere is my R analysis! Again, feel free to use this as you wish!\nlibrary(tidyverse)\nlibrary(RColorBrewer)\n\npokemon <- read_csv(\"scuffed_pokedex.csv\")\n\nnames(pokemon)\n\nnb.cols <- 18\nmycolors <- colorRampPalette(brewer.pal(8, \"YlOrRd\"))(nb.cols)\n\npokemon %>% \n  mutate(pokemon_type = str_to_title(pokemon_type)) %>%\n  group_by(pokemon_type) %>%\n  summarise(avg_power = mean(pokemon_power, na.rm = TRUE),\n            avg_accuracy = mean(pokemon_accuracy, na.rm = TRUE)) %>%\n  ggplot(aes(x = avg_power, y = reorder(pokemon_type, avg_power), fill = reorder(pokemon_type, avg_power)))+\n  geom_col(show.legend = FALSE, color = \"black\") +\n  labs(x = \"Average power\",\n       y = \"Pokemon type\",\n       title = \"FIRE! The Best Pokemon Type For Damage Output Is...?\",\n       subtitle = \"Based on an Average of All Moves Per Pokemon Type\",\n       caption = \"Source: Pokédex of Kanto, Johto, and Hoenn Regions @ Kaggle.com\") +\n  scale_fill_manual(values = mycolors) +\n  theme(plot.background = element_blank(),\n        panel.background = element_blank(),\n        axis.ticks.y = element_blank(),\n        panel.grid.major.x = element_line(color = \"grey\"))\n\n\nnb.cols <- 18\nmycolors <- colorRampPalette(brewer.pal(8, \"Blues\"))(nb.cols)\n\npokemon %>% \n  mutate(pokemon_type = str_to_title(pokemon_type)) %>%\n  group_by(pokemon_type) %>%\n  summarise(avg_power = mean(pokemon_power, na.rm = TRUE),\n            avg_accuracy = mean(pokemon_accuracy, na.rm = TRUE)) %>%\n  ggplot(aes(x = avg_accuracy, y = reorder(pokemon_type, avg_accuracy), fill = reorder(pokemon_type, avg_accuracy)))+\n  geom_col(show.legend = FALSE, color = \"black\") +\n  labs(x = \"Average accuracy\",\n       y = \"Pokemon type\",\n       title = \"Ouch! Who wins the bullseye competition?\",\n       subtitle = \"Based on an Average of All Moves Per Pokemon Type\",\n       caption = \"Source: Pokédex of Kanto, Johto, and Hoenn Regions @ Kaggle.com\") +\n  scale_fill_manual(values = mycolors) +\n  theme(plot.background = element_blank(),\n        panel.background = element_blank(),\n        axis.ticks.y = element_blank(),\n        panel.grid.major.x = element_line(color = \"grey\"))\n\n\npokemon %>% \n  group_by(pokemon_type) %>%\n  summarise(avg_power = mean(pokemon_power, na.rm = TRUE),\n            avg_accuarcy = mean(pokemon_accuracy, na.rm = TRUE)) %>%\n  ggplot(aes(x = avg_power, y = avg_accuarcy, color = pokemon_type)) +\n  geom_point()\n\n\nstats <- pokemon %>% \n  group_by(pokemon_type) %>%\n  summarise(avg_power = mean(pokemon_power, na.rm = TRUE),\n            avg_accuarcy = mean(pokemon_accuracy, na.rm = TRUE))\n            \nmodel <- lm(data = stats, avg_accuracy ~ avg_power)\nplot(model)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Brian",
    "section": "",
    "text": "Who am I?\nI am a next generation Data Scientist who is eager to learn and apply my knowledge to real-world problems. I have completed relevant coursework and gained proficiency in programming languages such as Python, R, and SQL. Additionally, I have experience working with data visualization tools and statistical analysis techniques. I am committed to continuous learning and staying up-to-date with the latest developments in the field of data science. I am excited to contribute my skills and learn from experienced professionals in the industry.\n\n\nWhere do I come from?\nI was born in Pasco, Washington, a small city in the southeastern part of the state. Pasco is part of the Tri-Cities area, along with Richland and Kennewick, and is known for its agricultural industry, particularly the cultivation of potatoes, apples, and wine grapes. I enjoyed the rural atmosphere of Pasco, with its open fields, orchards, and vineyards.\n\n\n\nPasco, Washington\n\n\nBefore finishing 1st grade, I moved to Salem, Oregon, a mid-sized city in the heart of the Willamette Valley. Salem is known for its farms and vineyards that produce some of the best wine and food in the state. Growing up in Salem, I was immersed in the outdoors and enjoyed activities such as hiking, camping, and running. Salem also has a rich history, with landmarks like the Oregon State Capitol and Willamette University, which is the oldest university in the west. However, as I got older, I also became aware of some of the social and economic challenges faced by many families in the area, such as poverty, limited job opportunities, and inadequate access to healthcare. My family and I suffered poverty and food instability before I graduated high school. Despite these challenges, I feel a strong connection to Salem and its people, and I am grateful for the experiences and values that I gained from growing up in this community.\n\n\n\nSalem, Oregon"
  },
  {
    "objectID": "posts/GymRat_Plotly/index.html",
    "href": "posts/GymRat_Plotly/index.html",
    "title": "Do You Like Stretching? I would Reconsider!",
    "section": "",
    "text": "Stretching is not a good method of building muscle for several reasons. First, stretching is primarily focused on increasing flexibility and range of motion, rather than building muscle mass or strength. While stretching can help prepare the muscles for exercise and prevent injury, it is not a sufficient method of building muscle. Second, stretching alone does not provide enough resistance or tension on the muscles to stimulate muscle growth. To build muscle, the body needs to be challenged with weight or resistance training. Finally, stretching may actually reduce muscle strength by decreasing muscle activation and power output. While stretching can be a useful addition to a muscle-building routine, it should not be relied upon as the primary method for building muscle mass and strength."
  },
  {
    "objectID": "posts/GymRat_Plotly/index.html#data-wrangling-for-plot-1",
    "href": "posts/GymRat_Plotly/index.html#data-wrangling-for-plot-1",
    "title": "Do You Like Stretching? I would Reconsider!",
    "section": "Data Wrangling For Plot 1",
    "text": "Data Wrangling For Plot 1\n\n\nCode\ngymDs <- read_csv(\"megaGymDataset.csv\")\n\n#head(gymDs, 5)\n#names(gymDs)\n\nds <- gymDs %>%\n  mutate(ID = ...1,\n         Level = factor(Level, levels = c(\"Beginner\", \"Intermediate\", \"Expert\")),\n         Type = as.factor(Type)) %>%\n  select(-...1) %>% \n  drop_na()"
  },
  {
    "objectID": "posts/GymRat_Plotly/index.html#plot-1",
    "href": "posts/GymRat_Plotly/index.html#plot-1",
    "title": "Do You Like Stretching? I would Reconsider ASAP!",
    "section": "Plot 1",
    "text": "Plot 1\n\n\nCode\nmyTheme <- theme(text = element_text(family = \"Futura Medium\"),\n                 plot.margin = margin(0.5, 0.5, 0.5, 0.5, unit = \"cm\"),\n                 plot.title = element_text(size = 15, family = \"Futura Condensed ExtraBold\"),\n                 plot.subtitle = element_text(size = 10, family = \"Futura Medium\"),\n                 strip.text.y = element_text(angle = 90, size = 10, family = \"Futura Condensed ExtraBold\"),\n                 strip.placement = \"inside\",\n                 axis.title.x = element_text(margin = margin(t = 0.5, b = 0.5, unit = \"cm\")),\n                 axis.title.y = element_blank(),\n                 axis.text = element_text(size = 9),\n                 legend.position = \"none\",\n                 panel.grid.major.y = element_blank())\n\n\nplotDs <- ds %>% \n  group_by(Type, Level) %>%\n  summarize(meanRating = mean(Rating)) %>%\n  arrange(Type, meanRating) %>%\n  ungroup()\n\np <- plotDs %>%\n  ggplot(aes(x = meanRating, \n             y = reorder_within(Type, meanRating, Level),\n             fill = fct_reorder(Type, meanRating))) +\n  geom_col(color = \"black\") + \n  facet_grid(rows = vars(Level), \n             scales = \"free_y\", \n             switch = \"y\", \n             space = \"free_y\") +\n  scale_y_reordered() +\n  scale_fill_brewer(palette = \"PuBuGn\") +\n  labs(title = \"Are You a Stretch Fiend? You Should Reconsider\",\n       caption = \"Based on the average rating of each exercise type for each individual's current level\",\n       x = \"Average Rating of Each Exercise Type\",\n       fill = \"Workout Types\") + theme_minimal() +\n  myTheme \n\nggplotly(p)"
  },
  {
    "objectID": "posts/GymRat_Plotly/index.html#data-wrangling-for-plot-1-1",
    "href": "posts/GymRat_Plotly/index.html#data-wrangling-for-plot-1-1",
    "title": "Do You Like Stretching? I would Reconsider ASAP!",
    "section": "Data Wrangling For Plot 1",
    "text": "Data Wrangling For Plot 1\n\n\nCode\ngymDs <- gymDs %>%\n  mutate(ID = ...1,\n         Level = factor(Level, levels = c(\"Beginner\", \"Intermediate\", \"Expert\")),\n         Type = as.factor(Type)) %>%\n  select(-...1) %>% \n  drop_na()"
  },
  {
    "objectID": "posts/GymRat_Plotly/index.html#plot-2",
    "href": "posts/GymRat_Plotly/index.html#plot-2",
    "title": "Do You Like Stretching? I would Reconsider ASAP!",
    "section": "Plot 2",
    "text": "Plot 2\n\n\nCode\nmyTheme <- theme(text = element_text(family = \"Futura Medium\"),\n                 plot.margin = margin(0.5, 0.5, 0.5, 0.5, unit = \"cm\"),\n                 plot.title = element_text(size = 15, family = \"Futura Condensed ExtraBold\"),\n                 strip.text.y = element_text(angle = 90, size = 10, family = \"Futura Condensed ExtraBold\"),\n                 strip.placement = \"outside\",\n                 axis.title.x = element_text(margin = margin(t = 0.5, b = 0.5, unit = \"cm\")),\n                 axis.title.y = element_blank(),\n                 axis.text = element_text(size = 9),\n                 legend.position = \"none\",\n                 panel.grid.major.y = element_blank())\n\n\nplotDs <- gymDs %>% \n  group_by(Type, Level) %>%\n  summarize(meanRating = mean(Rating)) %>%\n  arrange(Type, meanRating) %>%\n  ungroup()\n\np <- plotDs %>%\n  ggplot(aes(x = meanRating, \n             y = reorder_within(Type, meanRating, Level),\n             fill = fct_reorder(Type, meanRating))) +\n  geom_col(color = \"black\") + \n  facet_grid(rows = vars(Level), \n             scales = \"free_y\", \n             switch = \"y\", \n             space = \"free_y\") +\n  scale_y_reordered() +\n  scale_fill_brewer(palette = \"PuBuGn\") +\n  labs(title = \"Are You a Stretch Fiend? You Should Reconsider\",\n       x = NULL,\n       y = \"\",\n       fill = \"Workout Types\") + theme_minimal() +\n  myTheme \n\nggplotly(p)"
  },
  {
    "objectID": "posts/GymRat_Plotly/index.html#using-plotly-for-plot-1",
    "href": "posts/GymRat_Plotly/index.html#using-plotly-for-plot-1",
    "title": "Do You Like Stretching? I would Reconsider!",
    "section": "Using Plotly for Plot 1",
    "text": "Using Plotly for Plot 1\n\n\nCode\nmyTheme <- theme(text = element_text(family = \"Futura Medium\"),\n                 plot.margin = margin(0.5, 0.5, 0.5, 0.5, unit = \"cm\"),\n                 plot.title = element_text(size = 15, family = \"Futura Condensed ExtraBold\"),\n                 plot.subtitle = element_text(size = 10, family = \"Futura Medium\"),\n                 strip.text.y = element_text(angle = 0, size = 10, family = \"Futura Condensed ExtraBold\"),\n                 strip.placement = \"inside\",\n                 axis.title.x = element_text(margin = margin(t = 0.5, b = 0.5, unit = \"cm\")),\n                 axis.title.y = element_blank(),\n                 axis.text = element_text(size = 9),\n                 legend.position = \"none\",\n                 panel.grid.major.y = element_blank())\n\n\nplotDs <- ds %>% \n  group_by(Type, Level) %>%\n  summarize(meanRating = mean(Rating)) %>%\n  arrange(Type, meanRating) %>%\n  ungroup()\n\np <- plotDs %>%\n  highlight_key(., ~reorder_within(Type, meanRating, Level)) %>%\n  ggplot(aes(x = meanRating, \n             y = reorder_within(Type, meanRating, Level),\n             fill = fct_reorder(Type, meanRating),\n             text = paste0(\"Rating: \", round(meanRating,2),\n                           \"<br>Type: \", Type))) +\n  geom_col(color = \"black\") + \n  facet_grid(rows = vars(Level), \n             scales = \"free_y\", \n             switch = \"y\", \n             space = \"free_y\") +\n  scale_y_reordered() +\n  scale_fill_brewer(palette = \"PuBuGn\") +\n  labs(title = \"Ranking Exercise Type According to Experience Level of Individuals\",\n       x = \"Average Rating of Each Exercise Type\",\n       fill = \"Workout Types\") + \n  theme_minimal() +\n  myTheme \n\n\nggplotly(p, tooltip = \"text\") %>%\n  config(displayModeBar = FALSE) %>%\n  highlight(on = \"plotly_hover\", off = \"plotly_doubleclick\") %>%\n  layout(\n    uniformtext=list(minsize=8, mode='hide'),\n    margin = list(b = 70, l = 140, r = 140)\n  )"
  },
  {
    "objectID": "posts/GymRat_Plotly/index.html#data-wrangling-for-plot-2",
    "href": "posts/GymRat_Plotly/index.html#data-wrangling-for-plot-2",
    "title": "Do You Like Stretching? I would Reconsider!",
    "section": "Data Wrangling For Plot 2",
    "text": "Data Wrangling For Plot 2\n\n\nCode\nplotDs2 <- ds %>%\n  group_by(BodyPart, Level) %>%\n  summarize(meanRating = mean(Rating))\n\nhead(plotDs2)\n\n\n# A tibble: 6 × 3\n# Groups:   BodyPart [3]\n  BodyPart   Level        meanRating\n  <chr>      <fct>             <dbl>\n1 Abdominals Beginner           6.64\n2 Abdominals Intermediate       8.07\n3 Abductors  Beginner           1.6 \n4 Abductors  Intermediate       5.47\n5 Adductors  Beginner           4   \n6 Adductors  Intermediate       8.15"
  },
  {
    "objectID": "posts/GymRat_Plotly/index.html#using-for-plot-1",
    "href": "posts/GymRat_Plotly/index.html#using-for-plot-1",
    "title": "Do You Like Stretching? I would Reconsider ASAP!",
    "section": "Using for Plot 1",
    "text": "Using for Plot 1\n\n\nCode\nmyTheme <- theme(text = element_text(family = \"Futura Medium\"),\n                 plot.margin = margin(0.5, 0.5, 0.5, 0.5, unit = \"cm\"),\n                 plot.title = element_text(size = 15, family = \"Futura Condensed ExtraBold\"),\n                 strip.text.y = element_text(angle = 90, size = 10, family = \"Futura Condensed ExtraBold\"),\n                 strip.placement = \"outside\",\n                 axis.title.x = element_text(margin = margin(t = 0.5, b = 0.5, unit = \"cm\")),\n                 axis.title.y = element_blank(),\n                 axis.text = element_text(size = 9),\n                 legend.position = \"none\",\n                 panel.grid.major.y = element_blank())\n\n\nplotDs <- gymDs %>% \n  group_by(Type, Level) %>%\n  summarize(meanRating = mean(Rating)) %>%\n  arrange(Type, meanRating) %>%\n  ungroup()\n\np <- plotDs %>%\n  ggplot(aes(x = meanRating, \n             y = reorder_within(Type, meanRating, Level),\n             fill = fct_reorder(Type, meanRating))) +\n  geom_col(color = \"black\") + \n  facet_grid(rows = vars(Level), \n             scales = \"free_y\", \n             switch = \"y\", \n             space = \"free_y\") +\n  scale_y_reordered() +\n  scale_fill_brewer(palette = \"PuBuGn\") +\n  labs(title = \"Are You a Stretch Fiend? You Should Reconsider\",\n       x = NULL,\n       y = \"\",\n       fill = \"Workout Types\") + theme_minimal() +\n  myTheme \n\n#ggplotly(p)"
  },
  {
    "objectID": "about.html#where-do-i-come-from",
    "href": "about.html#where-do-i-come-from",
    "title": "Brian",
    "section": "Where do I come from?",
    "text": "Where do I come from?\nI was born in Pasco, Washington, a small city in the southeastern part of the state. Pasco is part of the Tri-Cities area, along with Richland and Kennewick, and is known for its agricultural industry, particularly the cultivation of potatoes, apples, and wine grapes. I enjoyed the rural atmosphere of Pasco, with its open fields, orchards, and vineyards.\n\n\n\nPasco, Washington\n\n\nBefore finishing 1st grade, I moved to Salem, Oregon, a mid-sized city in the heart of the Willamette Valley. Known for its lush greenery, Salem is surrounded by farms and vineyards that produce some of the best wine and food in the state. Growing up in Salem, I was immersed in the outdoors and enjoyed activities such as hiking, camping, and fishing. Salem also has a rich history, with landmarks like the Oregon State Capitol and Willamette University, which is the oldest university in the west. However, as I got older, I also became aware of some of the social and economic challenges faced by many families in the area, such as poverty, limited job opportunities, and inadequate access to healthcare. Despite these challenges, I feel a strong connection to Salem and its people, and I am grateful for the experiences and values that I gained from growing up in this community.\n\n\n\nSalem, Oregon"
  },
  {
    "objectID": "posts/SurvAnalysis_Parasite_RevealJS/index.html",
    "href": "posts/SurvAnalysis_Parasite_RevealJS/index.html",
    "title": "Does Temperature Kill Parasites Faster? Yes!",
    "section": "",
    "text": "Echinostoma trivolvis is a species of trematode parasite that commonly infects birds, mammals, and some reptiles. It is part of the family Echinostomatidae, which includes several other species of trematodes that infect animals and humans. Echinostoma trivolvis has a complex life cycle that involves multiple hosts, including snails, birds, and mammals. The adult worms inhabit the small intestine of their hosts, where they feed on blood and nutrients. Infection with Echinostoma trivolvis can cause a range of symptoms, including abdominal pain, diarrhea, and malnutrition. The parasite is found throughout North America, particularly in wetlands and other aquatic environments where its intermediate hosts, freshwater snails, are abundant."
  },
  {
    "objectID": "posts/GymRat_Plotly/index.html#general-setup",
    "href": "posts/GymRat_Plotly/index.html#general-setup",
    "title": "Do You Like Stretching? I would Reconsider!",
    "section": "General Setup",
    "text": "General Setup\n\n\nCode\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(ggtext)\nlibrary(RColorBrewer)\nlibrary(extrafont)\nlibrary(plotly)\nlibrary(htmlwidgets)\n#font_import()\nloadfonts()"
  },
  {
    "objectID": "posts/GymRat_Plotly/index.html#using-for-plot-2",
    "href": "posts/GymRat_Plotly/index.html#using-for-plot-2",
    "title": "Do You Like Stretching? I would Reconsider!",
    "section": "Using for Plot 2",
    "text": "Using for Plot 2\n\n\nCode\nmyTheme <- theme(text = element_text(family = \"Futura Medium\"),\n                 plot.margin = margin(0.5, 0.5, 0.5, 0.5, unit = \"cm\"),\n                 plot.title = element_text(size = 15, family = \"Futura Condensed ExtraBold\"),\n                 strip.text.y = element_text(angle = 90, size = 10, family = \"Futura Condensed ExtraBold\"),\n                 strip.placement = \"outside\",\n                 axis.title.x = element_text(margin = margin(t = 0.5, b = 0.5, unit = \"cm\")),\n                 axis.title.y = element_blank(),\n                 axis.text = element_text(size = 9),\n                 legend.position = \"none\",\n                 panel.grid.major.y = element_blank())\n\n\n\n\n\n\n#ggplotly(p)"
  },
  {
    "objectID": "posts/SurvAnalysis_Parasite_RevealJS/index.html#parasite-presentation",
    "href": "posts/SurvAnalysis_Parasite_RevealJS/index.html#parasite-presentation",
    "title": "Does Temperature Kill Parasites Faster? Yes!",
    "section": "Parasite Presentation",
    "text": "Parasite Presentation"
  },
  {
    "objectID": "posts/SurvAnalysis_Parasite_RevealJS/index.html#echinostoma-trivolvis-vs.-pesticides",
    "href": "posts/SurvAnalysis_Parasite_RevealJS/index.html#echinostoma-trivolvis-vs.-pesticides",
    "title": "Does Temperature Kill Parasites Faster? Yes!",
    "section": "Echinostoma trivolvis Vs. Pesticides",
    "text": "Echinostoma trivolvis Vs. Pesticides"
  }
]
{
  "hash": "fc157d37aee400f0d2a0bdb904e1a001",
  "result": {
    "markdown": "---\ntitle: \"Predicting the Province of Origin for Pinot Wines Based on Their Individual Descriptions\"\nauthor: \"Brian Cervantes Alvarez\"\ndate: \"03-01-2023\"\nimage: pinot.jpeg\nformat:\n  html:\n    toc: true\n    toc-location: right\n    html-math-method: katex\noutput: html_document\ncode-fold: false\ncategories: [R, machine learning, random forest, classification]\n---\n\n\n\n![](pinot.jpeg)\n\n## Purpose\n\nThe purpose of this project was to develop a predictive model for identifying the province of origin for wines based on descriptions provided by critics. To achieve this goal, a random forest model was built and evaluated for its performance, achieving a kappa score of 0.82. This project aimed to provide a useful tool for wine connoisseurs and industry professionals in identifying the origin of wines based on their sensory characteristics.\n\n\n## Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(caret)\nlibrary(rpart)\nlibrary(tidytext)\nlibrary(SnowballC)\nwine = read_rds(\"pinot.rds\") \n```\n:::\n\n\n## Feature Engineering\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(word)`\nJoining with `by = join_by(id)`\n```\n:::\n:::\n\n\n## Specification\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(504) \n\nctrl <- trainControl(method = \"cv\", number = 3)\n\n\nwine_index <- createDataPartition(wino$province, p = 0.80, list = FALSE)\ntrain <- wino[ wine_index, ]\ntest <- wino[-wine_index, ]\n\nfit <- train(province ~ .,\n             data = train, \n             method = \"rf\",\n             ntree = 100,\n             tuneLength = 15,\n             nodesize = 10,\n             verbose = TRUE,\n             trControl = ctrl,\n             metric = \"Kappa\")\n```\n:::\n\n\n## Model Performance\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconfusionMatrix(predict(fit, test),factor(test$province))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n                   Reference\nPrediction          Burgundy California Casablanca_Valley Marlborough New_York\n  Burgundy               216          5                 0           0        1\n  California              13        758                14          23       19\n  Casablanca_Valley        0          0                10           0        0\n  Marlborough              0          0                 0          12        0\n  New_York                 0          0                 0           0        0\n  Oregon                   9         28                 2          10        6\n                   Reference\nPrediction          Oregon\n  Burgundy              10\n  California            62\n  Casablanca_Valley      0\n  Marlborough            0\n  New_York               0\n  Oregon               475\n\nOverall Statistics\n                                          \n               Accuracy : 0.8793          \n                 95% CI : (0.8627, 0.8945)\n    No Information Rate : 0.4728          \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.8069          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: Burgundy Class: California Class: Casablanca_Valley\nSensitivity                   0.9076            0.9583                 0.384615\nSpecificity                   0.9889            0.8515                 1.000000\nPos Pred Value                0.9310            0.8526                 1.000000\nNeg Pred Value                0.9847            0.9579                 0.990379\nPrevalence                    0.1423            0.4728                 0.015541\nDetection Rate                0.1291            0.4531                 0.005977\nDetection Prevalence          0.1387            0.5314                 0.005977\nBalanced Accuracy             0.9482            0.9049                 0.692308\n                     Class: Marlborough Class: New_York Class: Oregon\nSensitivity                    0.266667         0.00000        0.8684\nSpecificity                    1.000000         1.00000        0.9512\nPos Pred Value                 1.000000             NaN        0.8962\nNeg Pred Value                 0.980132         0.98446        0.9370\nPrevalence                     0.026898         0.01554        0.3270\nDetection Rate                 0.007173         0.00000        0.2839\nDetection Prevalence           0.007173         0.00000        0.3168\nBalanced Accuracy              0.633333         0.50000        0.9098\n```\n:::\n:::\n\n\n## Re-fit and evaluation\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1504)\n\nwine_index <- createDataPartition(wino$province, p = 0.80, list = FALSE)\ntrain <- wino[ wine_index, ]\ntest <- wino[-wine_index, ]\n\n# example spec for knn\nfit_final <- train(province ~ .,\n             data = train, \n             method = \"rf\",\n             tuneGrid = fit$bestTune) \n# The last line means we will fit a model using the best tune parameters your CV found above.\n```\n:::\n\n\n\n## Final Model Performance\n\n::: {.cell}\n\n```{.r .cell-code}\nconfusionMatrix(predict(fit_final, test),factor(test$province))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n                   Reference\nPrediction          Burgundy California Casablanca_Valley Marlborough New_York\n  Burgundy               219          7                 0           0        0\n  California               7        752                12          13       20\n  Casablanca_Valley        0          0                12           0        0\n  Marlborough              0          1                 0          22        0\n  New_York                 0          0                 0           0        1\n  Oregon                  12         31                 2          10        5\n                   Reference\nPrediction          Oregon\n  Burgundy               7\n  California            55\n  Casablanca_Valley      0\n  Marlborough            0\n  New_York               0\n  Oregon               485\n\nOverall Statistics\n                                          \n               Accuracy : 0.8912          \n                 95% CI : (0.8753, 0.9057)\n    No Information Rate : 0.4728          \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.8274          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: Burgundy Class: California Class: Casablanca_Valley\nSensitivity                   0.9202            0.9507                 0.461538\nSpecificity                   0.9902            0.8787                 1.000000\nPos Pred Value                0.9399            0.8754                 1.000000\nNeg Pred Value                0.9868            0.9521                 0.991571\nPrevalence                    0.1423            0.4728                 0.015541\nDetection Rate                0.1309            0.4495                 0.007173\nDetection Prevalence          0.1393            0.5134                 0.007173\nBalanced Accuracy             0.9552            0.9147                 0.730769\n                     Class: Marlborough Class: New_York Class: Oregon\nSensitivity                     0.48889       0.0384615        0.8867\nSpecificity                     0.99939       1.0000000        0.9467\nPos Pred Value                  0.95652       1.0000000        0.8899\nNeg Pred Value                  0.98606       0.9850478        0.9450\nPrevalence                      0.02690       0.0155409        0.3270\nDetection Rate                  0.01315       0.0005977        0.2899\nDetection Prevalence            0.01375       0.0005977        0.3258\nBalanced Accuracy               0.74414       0.5192308        0.9167\n```\n:::\n:::\n\n\n\n## Conclusion\n\nA kappa value of 0.82 indicates a very good level of agreement between the predictions of the random forest model and the actual outcomes. Kappa is a statistical measure of inter-rater agreement, which is commonly used to evaluate the performance of classification models.\n\nIn the context of a random forest model, the kappa value measures how well the model predicts the correct class labels for a given set of data. A kappa value of 0.82 indicates that the model's predictions are in very good agreement with the true class labels, with a high degree of precision and accuracy.\n\nOverall, a kappa value of 0.82 suggests that the random forest model is performing very well, and can be considered a reliable predictor of the target variable in the dataset.\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
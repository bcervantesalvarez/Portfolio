{
  "hash": "aedb05699eab0995d9c19be3a2f2f25f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Pinot Province Prediction\"\nauthor: \"Brian Cervantes Alvarez\"\ndate: \"03-01-2023\"\ndescription: \"Our project sets a new bar in wine origin identification, transforming how industry professionals use critic data.\"\nteaser: \"Classifying wine origin with advanced data analysis and ML.\"\ncategories: [\"Machine Learning\"]\nimage: /assets/images/pinot.jpeg\nformat:\n  html:\n    toc: true\n    toc-location: right\n    html-math-method: katex\n    page-layout: article\noutput: html_document\ncode-fold: false\nexecute:\n  warning: false\n  message: false\n---\n\n\n\n\n\n![](/assets/images/pinot.jpeg)\n\n## Purpose\n\nThe purpose of this project was to develop a predictive model for identifying the province of origin for wines based on descriptions provided by critics. To achieve this goal, a random forest model was built and evaluated for its performance, achieving a kappa score of 0.82. This project aimed to provide a useful tool for wine connoisseurs and industry professionals in identifying the origin of wines based on their sensory characteristics.\n\n## Setup\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(caret)\nlibrary(rpart)\nlibrary(tidytext)\nlibrary(SnowballC)\n```\n:::\n\n\n\n\n## Feature Engineering\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwine = read_rds(\"../../../assets/datasets/pinot.rds\") \n\nwine_words <- function(df, j, stem = T){ \n  data(stop_words)\n  words <- df %>%\n    unnest_tokens(word, description) %>%\n    anti_join(stop_words) %>%\n    filter(str_detect(string = word, pattern = \"[a-z+]\")) %>% # get rid weird non alphas \n    filter(str_length(word) >= 3) %>% # get rid of strings shorter than 3 characters \n    filter(!(word %in% c(\"wine\",\"pinot\", \"vineyard\"))) %>%\n    group_by(word) %>%\n    mutate(total=n()) %>%\n    ungroup()\n  \n  if(stem){\n    words <- words %>% \n      mutate(word = wordStem(word))\n  }\n  \n  words <- words %>% \n    count(id, word) %>% \n    group_by(id) %>% \n    mutate(exists = (n>0)) %>% \n    ungroup %>% \n    group_by(word) %>% \n    mutate(total = sum(n)) %>% \n    filter(total > j) %>% \n    pivot_wider(id_cols = id,\n                names_from = word,\n                values_from = exists,\n                values_fill = list(exists=0)) %>% \n    right_join(select(df,id,province)) %>% \n    select(-id) %>% \n    mutate(across(-province, ~replace_na(.x, F)))\n}\n\nwino <- wine_words(wine, j = 190, stem = T)\n```\n:::\n\n\n\n\n## Specification\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(504) \n\nctrl <- trainControl(method = \"cv\", number = 3)\n\n\nwine_index <- createDataPartition(wino$province, p = 0.80, list = FALSE)\ntrain <- wino[ wine_index, ]\ntest <- wino[-wine_index, ]\n\nfit <- train(province ~ .,\n             data = train, \n             method = \"rf\",\n             ntree = 100,\n             tuneLength = 15,\n             nodesize = 10,\n             verbose = TRUE,\n             trControl = ctrl,\n             metric = \"Kappa\")\n```\n:::\n\n\n\n\n## Model Performance\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconfusionMatrix(predict(fit, test),factor(test$province))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n                   Reference\nPrediction          Burgundy California Casablanca_Valley Marlborough New_York\n  Burgundy               216          5                 0           1        1\n  California              11        757                17          19       19\n  Casablanca_Valley        0          0                 7           0        0\n  Marlborough              0          0                 0          14        0\n  New_York                 0          0                 0           0        0\n  Oregon                  11         29                 2          11        6\n                   Reference\nPrediction          Oregon\n  Burgundy              10\n  California            58\n  Casablanca_Valley      0\n  Marlborough            0\n  New_York               0\n  Oregon               479\n\nOverall Statistics\n                                          \n               Accuracy : 0.8805          \n                 95% CI : (0.8639, 0.8956)\n    No Information Rate : 0.4728          \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.809           \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: Burgundy Class: California Class: Casablanca_Valley\nSensitivity                   0.9076            0.9570                 0.269231\nSpecificity                   0.9882            0.8594                 1.000000\nPos Pred Value                0.9270            0.8593                 1.000000\nNeg Pred Value                0.9847            0.9571                 0.988595\nPrevalence                    0.1423            0.4728                 0.015541\nDetection Rate                0.1291            0.4525                 0.004184\nDetection Prevalence          0.1393            0.5266                 0.004184\nBalanced Accuracy             0.9479            0.9082                 0.634615\n                     Class: Marlborough Class: New_York Class: Oregon\nSensitivity                    0.311111         0.00000        0.8757\nSpecificity                    1.000000         1.00000        0.9476\nPos Pred Value                 1.000000             NaN        0.8903\nNeg Pred Value                 0.981314         0.98446        0.9401\nPrevalence                     0.026898         0.01554        0.3270\nDetection Rate                 0.008368         0.00000        0.2863\nDetection Prevalence           0.008368         0.00000        0.3216\nBalanced Accuracy              0.655556         0.50000        0.9116\n```\n\n\n:::\n:::\n\n\n\n\n## Re-fit and evaluation\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1504)\n\nwine_index <- createDataPartition(wino$province, p = 0.80, list = FALSE)\ntrain <- wino[ wine_index, ]\ntest <- wino[-wine_index, ]\n\n# example spec for knn\nfit_final <- train(province ~ .,\n             data = train, \n             method = \"rf\",\n             tuneGrid = fit$bestTune) \n# The last line means we will fit a model using the best tune parameters your CV found above.\n```\n:::\n\n\n\n\n## Final Model Performance\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconfusionMatrix(predict(fit_final, test),factor(test$province))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n                   Reference\nPrediction          Burgundy California Casablanca_Valley Marlborough New_York\n  Burgundy               217          7                 0           0        0\n  California               9        754                12          13       20\n  Casablanca_Valley        0          0                12           0        0\n  Marlborough              0          1                 0          22        0\n  New_York                 0          0                 0           0        1\n  Oregon                  12         29                 2          10        5\n                   Reference\nPrediction          Oregon\n  Burgundy               7\n  California            59\n  Casablanca_Valley      0\n  Marlborough            0\n  New_York               0\n  Oregon               481\n\nOverall Statistics\n                                          \n               Accuracy : 0.8888          \n                 95% CI : (0.8728, 0.9035)\n    No Information Rate : 0.4728          \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.8234          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: Burgundy Class: California Class: Casablanca_Valley\nSensitivity                   0.9118            0.9532                 0.461538\nSpecificity                   0.9902            0.8719                 1.000000\nPos Pred Value                0.9394            0.8697                 1.000000\nNeg Pred Value                0.9854            0.9541                 0.991571\nPrevalence                    0.1423            0.4728                 0.015541\nDetection Rate                0.1297            0.4507                 0.007173\nDetection Prevalence          0.1381            0.5182                 0.007173\nBalanced Accuracy             0.9510            0.9126                 0.730769\n                     Class: Marlborough Class: New_York Class: Oregon\nSensitivity                     0.48889       0.0384615        0.8793\nSpecificity                     0.99939       1.0000000        0.9485\nPos Pred Value                  0.95652       1.0000000        0.8924\nNeg Pred Value                  0.98606       0.9850478        0.9418\nPrevalence                      0.02690       0.0155409        0.3270\nDetection Rate                  0.01315       0.0005977        0.2875\nDetection Prevalence            0.01375       0.0005977        0.3222\nBalanced Accuracy               0.74414       0.5192308        0.9139\n```\n\n\n:::\n:::\n\n\n\n\n## Conclusion\n\nThe kappa value of 0.82 for our random forest model signifies a high level of precision and accuracy, reflecting a very good agreement with the actual outcomes. This statistical measure, important for assessing classification model performance, confirms the model's efficacy in predicting the correct class labels. Thus, with a kappa value of 0.82, the model demonstrates reliable predictive performance.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}